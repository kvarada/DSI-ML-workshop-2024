{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Deep Learning\"\n",
        "format: \n",
        "    revealjs:\n",
        "      smaller: true\n",
        "      center: true\n",
        "jupyter: \n",
        "  kernelspec:\n",
        "    display_name: '571'\n",
        "    language: python\n",
        "    name: '571'\n",
        "---"
      ],
      "id": "7510c1cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mglearn\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "sys.path.append(os.path.join(os.path.abspath(\".\"), \"code\"))\n",
        "from deep_learning_code import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "id": "d78457e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning outcomes \n",
        "\\\n",
        "From this module, you will be able to \n",
        "\n",
        "- Explain the role of neural networks in machine learning, including their advantages and disadvantages.\n",
        "- Discuss why traditional methods are less effective for image data.\n",
        "- Gain a high-level understanding of transfer learning.\n",
        "- Differentiate between image classification and object detection.\n",
        "\n",
        "## Introduction to neural networks\n",
        "\\\n",
        "\n",
        "- Neural networks are very popular these days under the name deep learning.\n",
        "- Neural networks apply a sequence of transformations on your input data.\n",
        "- They can be viewed a generalization of linear models where we apply a series of transformations.\n",
        "- Here is graphical representation of a logistic regression model.\n",
        "- We have 4 features: x[0], x[1], x[2], x[3]\n"
      ],
      "id": "81d9db47"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import mglearn\n",
        "\n",
        "mglearn.plots.plot_logistic_regression_graph()"
      ],
      "id": "003524d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding a layer of transformations \n",
        "\\\n",
        "\n",
        "- Below we are adding one \"layer\" of transformations in between features and the target. \n",
        "- We are repeating the the process of computing the weighted sum multiple times.  \n",
        "- The **hidden units** (e.g., h[1], h[2], ...) represent the intermediate processing steps. \n"
      ],
      "id": "4211c1aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mglearn.plots.plot_single_hidden_layer_graph()"
      ],
      "id": "48834a24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One more layer of transformations \n",
        "\\\n",
        "\n",
        "- Now we are adding one more layer of transformations. \n"
      ],
      "id": "efc5d071"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mglearn.plots.plot_two_hidden_layer_graph()"
      ],
      "id": "91050ada",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural networks \n",
        "\\\n",
        "\n",
        "- A neural network is a model that's sort of like its own pipeline\n",
        "  - It involves a series of transformations (\"layers\") internally. \n",
        "  - The output is the prediction.\n",
        "\n",
        "- With a neural net, you specify the number of features after each transformation.\n",
        "  - In the above, it goes from 4 to 3 to 3 to 1.\n",
        "\n",
        "- To make them really powerful compared to the linear models, we apply a non-linear function to the weighted sum for each hidden node. \n",
        "- Neural network = neural net\n",
        "- Deep learning ~ using neural networks\n",
        "\n",
        "## Why neural networks?\n",
        "\\\n",
        "\n",
        "- They can learn very complex functions.\n",
        "  - The fundamental tradeoff is primarily controlled by the **number of layers** and **layer sizes**.\n",
        "  - More layers / bigger layers --> more complex model.\n",
        "  - You can generally get a model that will not underfit. \n",
        "\n",
        "- The work really well for structured data:\n",
        "  - 1D sequence, e.g. timeseries, language\n",
        "  - 2D image\n",
        "  - 3D image or video\n",
        "- They've had some incredible successes in the last 10 years.\n",
        "- Transfer learning (coming later today) is really useful.  \n",
        "\n",
        "## Why not neural networks?\n",
        "\\\n",
        "\n",
        "- Often they require a lot of data.\n",
        "- They require a lot of compute time, and, to be faster, specialized hardware called [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit).\n",
        "- They have huge numbers of hyperparameters are a huge pain to tune.\n",
        "  - Think of each layer having hyperparameters, plus some overall hyperparameters.\n",
        "  - Being slow compounds this problem.\n",
        "- They are not interpretable.\n",
        "- I don't recommend training them on your own without further training\n",
        "\n",
        "  - Good news\n",
        "    - You don't have to train your models from scratch in order to use them.\n",
        "    - I'll show you some ways to use neural networks without training them yourselves. \n",
        "\n",
        "## Deep learning software\n",
        "\\\n",
        "\n",
        "The current big players are:\n",
        "\n",
        "1. [PyTorch](http://pytorch.org)\n",
        "2. [TensorFlow](https://www.tensorflow.org)\n",
        "\n",
        "Both are heavily used in industry. If interested, see [comparison of deep learning software](https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software).\n",
        "\n",
        "<br><br>\n",
        "\n",
        "## Introduction to computer vision\n",
        "\\\n",
        "\n",
        "- [Computer vision](https://en.wikipedia.org/wiki/Computer_vision) refers to understanding images/videos, usually using ML/AI. It has many tasks of interest:\n",
        "    - image classification: is this a cat or a dog?\n",
        "    - object localization: where is the cat in this image?\n",
        "    - object detection: What are the various objects in the image? \n",
        "    - instance segmentation: What are the shapes of these various objects in the image? \n",
        "    - and much more...\n",
        "\n",
        "![](img/vision-apps.jpeg)\n",
        "\n",
        "<!-- Source: https://learning.oreilly.com/library/view/python-advanced-guide/9781789957211/--> \n",
        "\n",
        "In the last decade this field has been dominated by deep learning. We will explore **image classification** and **object detection**.\n",
        "\n",
        "## Image classification\n",
        "\\\n",
        "\n",
        "Have you used search in Google Photos? You can search for \"my photos of cat\" and it will retrieve photos from your libraries containing cats.\n",
        "This can be done using **image classification**, which is treated as a supervised learning problem, where we define a set of target classes (objects to identify in images), and train a model to recognize them using labeled example photos.\n",
        "\n",
        "## Image classification\n",
        "\\\n",
        "\n",
        "Image classification is not an easy problem because of the variations in the location of the object, lighting, background, camera angle, camera focus etc.\n",
        "\n",
        "![](img/cat_variation.png)\n",
        "<!-- [Source](https://developers.google.com/machine-learning/practica/image-classification) -->\n",
        "\n",
        "## Convolutional Neural Networks\n",
        "\\\n",
        "\n",
        "- A significant advancement in image classification was the application of **convolutional neural networks** (ConvNets or CNNs) to this problem. \n",
        "- [ImageNet Classification with Deep Convolutional\n",
        "Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
        "- Achieved a winning test error rate of 15.3%, compared to 26.2% achieved by the second-best entry in the ILSVRC-2012 competition. \n",
        "\n",
        "## Pre-trained models\n",
        "\\\n",
        "\n",
        "- In practice, very few people train an entire CNN from scratch because it requires a large dataset, powerful computers, and a huge amount of human effort to train the model.\n",
        "- Instead, a common practice is to download a pre-trained model and fine tune it for your task. This is called **transfer learning**.\n",
        "- Transfer learning is one of the most common techniques used in the context of computer vision and natural language processing.\n",
        "- It refers to using a model already trained on one task as a starting point for learning to perform another task\n",
        "\n",
        "## Pre-trained models\n",
        "\\\n",
        "\n",
        "- There are many famous deep learning architectures out there that have been very successful across a wide range of problems, e.g.: [AlexNet](https://arxiv.org/abs/1404.5997), [VGG](https://arxiv.org/abs/1409.1556), [ResNet](https://arxiv.org/abs/1512.03385), [Inception](https://arxiv.org/abs/1512.00567), [MobileNet](https://arxiv.org/abs/1801.04381), etc.\n",
        "\n",
        "- Many of these models have been pre-trained on famous datasets like ImageNet [[1](https://www.image-net.org/index.php), [2](https://en.wikipedia.org/wiki/ImageNet)]\n",
        "\n",
        "## ImageNet\n",
        "\\\n",
        "\n",
        "- [ImageNet](http://www.image-net.org/) is an image dataset that became a very popular benchmark in the field ~12 years ago. \n",
        "- Currently contains ~14 million labelled images with ~21,841 categories  \n",
        "- There are various versions with different number of images and classes\n",
        "    - ILSVRC, a popular annual competition in computer vision, uses a smaller subset of ImageNet. This subset consists of about 1.2 million training images, 50,000 validation images, and 150,000 testing images across 1,000 categories. \n",
        "- [Wikipedia article](https://en.wikipedia.org/wiki/ImageNet) on ImageNet\n",
        "\n",
        "## ImageNet classes \n",
        "\\\n",
        "\n",
        "- Here are some example classes. \n"
      ],
      "id": "10295102"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with open(\"data/imagenet_classes.txt\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "classes[100:110]"
      ],
      "id": "72ea039c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer learning \n",
        "\\\n",
        "\n",
        "- The idea of transfer learning is instead of developing a machine learning model from scratch, you use these available pre-trained models for your tasks either directly or by fine tuning them. \n",
        "- There are three common ways to use transfer learning in computer vision \n",
        "    1. Using pre-trained models out-of-the-box \n",
        "    2. Using pre-trained models as feature extractor and training your own model with these features\n",
        "    2. Starting with weights of pre-trained models and fine-tuning the weights for your task. \n",
        "- We will explore the first two approaches.     \n",
        "\n",
        "## Using pre-trained models out-of-the-box \n",
        "\\\n",
        "\n",
        "![](img/cnn-ex.png)\n",
        "\n",
        "<!-- Source: https://cezannec.github.io/Convolutional_Neural_Networks/ -->\n",
        "\n",
        "- Let's first try one of these models and apply it to our own problem right out of the box. \n",
        "\n",
        "\n",
        "## Using pre-trained models out-of-the-box \n",
        "\\\n",
        "\n",
        "- We can easily download famous models using the `torchvision.models` module. All models are available with pre-trained weights (based on ImageNet's 224 x 224 images)\n",
        "- We used a pre-trained model vgg16 which is trained on the ImageNet data. \n",
        "- We preprocess the given image. \n",
        "- We get prediction from this pre-trained model on a given image along with prediction probabilities.  \n",
        "- For a given image, this model will spit out one of the 1000 classes from ImageNet. \n",
        "\n",
        "## Using pre-trained models out-of-the-box {.scrollable}\n",
        "\n",
        "- Let's predict labels with associated probabilities for unseen images\n"
      ],
      "id": "57d46cc3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "images = glob.glob(\"data/test_images/*.*\")\n",
        "plt.figure(figsize=(5, 5));\n",
        "for image in images:\n",
        "    img = Image.open(image)\n",
        "    img.load()\n",
        "    \n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    df = classify_image(img)\n",
        "    print(df.to_string(index=False))\n",
        "    print(\"--------------------------------------------------------------\")"
      ],
      "id": "489ea19d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using pre-trained models out-of-the-box \n",
        "\\\n",
        "\n",
        "- We got these predictions without \"doing the ML ourselves\".\n",
        "- We are using **pre-trained** `vgg16` model which is available in `torchvision`.\n",
        "  - `torchvision` has many such pre-trained models available that have been very successful across a wide range of tasks: AlexNet, VGG, ResNet, Inception, MobileNet, etc.\n",
        "- Many of these models have been pre-trained on famous datasets like **ImageNet**. \n",
        "- So if we use them out-of-the-box, they will give us one of the ImageNet classes as classification. \n",
        "\n",
        "## Using pre-trained models out-of-the-box {.scrollable}\n",
        "\\\n",
        "\n",
        "- Let's try some images which are unlikely to be there in ImageNet. \n",
        "- It's not doing very well here because ImageNet doesn't have proper classes for these images.\n"
      ],
      "id": "c5be6825"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict labels with associated probabilities for unseen images\n",
        "images = glob.glob(\"data/random_img/*.*\")\n",
        "for image in images:\n",
        "    img = Image.open(image)\n",
        "    img.load()\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    df = classify_image(img)\n",
        "    print(df.to_string(index=False))\n",
        "    print(\"--------------------------------------------------------------\")"
      ],
      "id": "6e71170a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using pre-trained models out-of-the-box\n",
        "\\\n",
        "\n",
        "- Here we are using pre-trained models out-of-the-box. \n",
        "- Can we use pre-trained models for our own classification problem with our classes? \n",
        "- Yes!! We have two options here:\n",
        "    1. Add some extra layers to the pre-trained network to suit our particular task\n",
        "    2. Pass training data through the network and save the output to use as features for training some other model\n",
        "\n",
        "\n",
        "## Using pre-trained models to extract features \n",
        "\\\n",
        "\n",
        "- Let's use pre-trained models to extract features.\n",
        "- We will pass our specific data through a pre-trained network to get a feature vector for each example in the data. \n",
        "- The feature vector is usually extracted from the last layer, before the classification layer from the pre-trained network. \n",
        "- You can think of each layer a transformer applying some transformations on the input received to that later. \n",
        "\n",
        "![](img/cnn-ex.png)\n",
        "\n",
        "\n",
        "## Using pre-trained models to extract features \n",
        "\\\n",
        "\n",
        "- Once we extract these feature vectors for all images in our training data, we can train a machine learning classifier such as logistic regression or random forest. \n",
        "- This classifier will be trained on our classes using feature representations extracted from the pre-trained models.  \n",
        "- Let's try this out. \n",
        "- It's better to train such models with GPU. Since our dataset is quite small, we won't have problems running it on a CPU. \n",
        "\n",
        "## Using pre-trained models to extract features \n",
        "\\\n",
        "\n",
        "Let's look at some sample images in the dataset. \n"
      ],
      "id": "46a7094e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    data_dir = 'data/food/'\n",
        "    image_datasets, dataloaders = read_data(data_dir)\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
        "    class_names = image_datasets[\"train\"].classes\n",
        "    inputs, classes = next(iter(dataloaders[\"valid\"]))\n",
        "    plt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample valid Images\")\n",
        "    plt.imshow(np.transpose(utils.make_grid(inputs, padding=1, normalize=True),(1, 2, 0)));"
      ],
      "id": "373386ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset statistics\n",
        "\\\n",
        "\n",
        "Here is the stat of our toy dataset. \n"
      ],
      "id": "f114fec3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    print(f\"Classes: {image_datasets['train'].classes}\")\n",
        "    print(f\"Class count: {image_datasets['train'].targets.count(0)}, {image_datasets['train'].targets.count(1)}, {image_datasets['train'].targets.count(2)}\")\n",
        "    print(f\"Samples:\", len(image_datasets[\"train\"]))\n",
        "    print(f\"First sample: {image_datasets['train'].samples[0]}\")"
      ],
      "id": "3a436615",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using pre-trained models to extract features \n",
        "\\\n",
        "\n",
        "- Now for each image in our dataset, we'll extract a feature vector from a pre-trained model called densenet121, which is trained on the ImageNet dataset.  \n"
      ],
      "id": "b796bc09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "densenet = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\n",
        "densenet.classifier = nn.Identity()  # remove that last \"classification\" layer\n",
        "Z_train, y_train, Z_valid, y_valid = get_features(\n",
        "    densenet, dataloaders[\"train\"], dataloaders[\"valid\"]\n",
        ")"
      ],
      "id": "7362b352",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shape of the feature vector\n",
        "\\\n",
        "\n",
        "- Now we have extracted feature vectors for all examples. What's the shape of these features?\n"
      ],
      "id": "3a7dea21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Z_train.shape"
      ],
      "id": "9dc713ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The size of each feature vector is 1024 because the size of the last layer in densenet architecture is 1024.  \n",
        "\n",
        "![](img/densenet-architecture.png)\n",
        "\n",
        "[Source](https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a)\n",
        "\n",
        "## A feature vector given by densenet \n",
        "\\ \n",
        "\n",
        "- Let's examine the feature vectors. \n"
      ],
      "id": "d547cd78"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.DataFrame(Z_train).head()"
      ],
      "id": "ad6af8a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The features are hard to interpret but they have some important information about the images which can be useful for classification.  \n",
        "\n",
        "## Logistic regression with the extracted features \n",
        "\\\n",
        "\n",
        "- Let's try out logistic regression on these extracted features. \n"
      ],
      "id": "d75b0bcc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000))\n",
        "pipe.fit(Z_train, y_train)\n",
        "print(\"Training score: \", pipe.score(Z_train, y_train))"
      ],
      "id": "1ea238d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pipe.score(Z_valid, y_valid)\n",
        "print(\"Validation score: \", pipe.score(Z_valid, y_valid))"
      ],
      "id": "fba52dbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- This is great accuracy for so little data and little effort!!!\n",
        "\n",
        "\n",
        "## Sample predictions\n",
        "\\\n",
        "\n",
        "Let's examine some sample predictions on the validation set.  \n"
      ],
      "id": "c3774356"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show predictions for 25 images in the validation set (5 rows of 5 images)\n",
        "show_predictions(pipe, Z_valid, y_valid, dataloaders['valid'], class_names, num_images=40)"
      ],
      "id": "be1f4d45",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Object detection using [YOLO](https://docs.ultralytics.com/)\n",
        "\\\n",
        "\n",
        "- Another useful task and tool to know is object detection using YOLO model. \n",
        "- Let's identify objects in a sample image using a pretrained model called YOLO5\n"
      ],
      "id": "a7480939"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Load image\n",
        "img = 'data/yolo_test/3356700488_183566145b.jpg'\n",
        "\n",
        "# Perform inference\n",
        "results = model(img)\n",
        "\n",
        "# Print results\n",
        "results.print()  # prints results to console\n",
        "\n",
        "# Show results\n",
        "results.show()  # displays image with bounding boxes\n",
        "\n",
        "# Save results\n",
        "# results.save()  # save image with detections to 'runs/detect/exp'"
      ],
      "id": "29ecbc2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary \n",
        "\\\n",
        "\n",
        "- Neural networks are a flexible class of models.\n",
        "  - They are hard to train\n",
        "  - They are particular powerful for structured input like images, videos, audio, etc.\n",
        "- The good news is we can use pre-trained neural networks.\n",
        "  - This saves us a huge amount of time/cost/effort/resources.\n",
        "  - We can use these pre-trained networks directly or use them as feature transformers. "
      ],
      "id": "4166f8a0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "571",
      "language": "python",
      "name": "571"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}